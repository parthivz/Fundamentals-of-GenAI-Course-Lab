{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FO4He6AuvCvD",
    "outputId": "2b550075-b1b0-4b3a-8869-204dd86627d4"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qT84LO_ryWGC",
    "outputId": "dbb22fe7-f7df-4839-9b06-9349accd023b"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade  textblob gensim pytorch-nlp swifter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6h9-CflyyWIf",
    "outputId": "036f7adb-71fd-4f5d-cbb0-99cdb17eff81"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import sys\n",
    "from textblob import TextBlob, Word\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import swifter\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import warnings\n",
    "import nltk\n",
    "\n",
    "max_length = 100\n",
    "# Hyperparameters\n",
    "embedding_dim = 100  # embedding dimension\n",
    "hidden_dim = 100  # LSTM hidden dimensions\n",
    "num_layers = 1  # number of LSTM layers\n",
    "batch_size = 64  # batch size\n",
    "num_epochs = 10  # number of epochs to train\n",
    "lr = 0.001  # learning rate\n",
    "\n",
    "\n",
    "def set_seeds_and_trace():\n",
    "  os.environ['PYTHONHASHSEED'] = '0'\n",
    "  np.random.seed(42)\n",
    "  random.seed(42)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "set_seeds_and_trace()\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('punkt')\n",
    "textblob_tokenizer = lambda x: TextBlob(x).words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0oENn5_JyWLG",
    "outputId": "acf13b8e-ab9f-4415-90e9-b4962b31dfc5"
   },
   "outputs": [],
   "source": [
    "%%writefile get_data.sh\n",
    "if [ ! -f ner_dataset.csv ]; then\n",
    "  wget -O ner_dataset.csv https://www.dropbox.com/s/mbfv0x988mdj89h/ner_dataset.csv?dl=0\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CkxCOJz_yWNu"
   },
   "outputs": [],
   "source": [
    "!bash get_data.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "18V5m92oyWQK",
    "outputId": "73e81c9e-4d85-4cf5-e802-c89cd733828c"
   },
   "outputs": [],
   "source": [
    "data= pd.read_csv(\"./ner_dataset.csv\",encoding=\"latin1\")\n",
    "data = data.fillna(method='ffill')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8RzRPJPTyWS2",
    "outputId": "3f5ea133-789f-4457-8d8a-b7b9f7bc2c2d"
   },
   "outputs": [],
   "source": [
    "print(\"Unique Words in corpus:\",data['Word'].nunique())\n",
    "print(\"Unique Tag in corpus:\",data['Tag'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oYF9u8Dp13YW"
   },
   "outputs": [],
   "source": [
    "words = list(set(data['Word'].values))\n",
    "words.append(\"ENDPAD\")\n",
    "num_words = len(words)\n",
    "tags = list(set(data['Tag'].values))\n",
    "num_tags = len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XAv4P3G1-7D"
   },
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "  def __init__(self,data):\n",
    "    self.n_sent = 1 #counter\n",
    "    self.data = data\n",
    "    agg_func = lambda s:[(w,p,t) for w,p,t in zip(s['Word'].tolist(),s['POS'].tolist(),s['Tag'].tolist())]\n",
    "    self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "    self.sentences = [s for s in self.grouped]\n",
    "\n",
    "\n",
    "\n",
    "getter = SentenceGetter(data)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9tP7TzZ71-9d",
    "outputId": "21a04766-88d7-44ae-8a43-8c51e34ab64d"
   },
   "outputs": [],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R4IPXmOQ1_Ci"
   },
   "outputs": [],
   "source": [
    "word2idx =  {w : i+1 for i,w in enumerate(words)}\n",
    "tag2idx  =  {t : i for i,t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ox9i1Zc1_FN",
    "outputId": "45b3ebed-53e3-486d-8299-eef1f001d577"
   },
   "outputs": [],
   "source": [
    "tokenized_sentences = [[word2idx[w[0]] for w in s]for s in sentences]\n",
    "\n",
    "tokenized_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "etE_inANTDNU",
    "outputId": "9449fa46-2634-4b1e-8430-f3e29ea86f4d"
   },
   "outputs": [],
   "source": [
    "maximum_length = max([len(x) for x in tokenized_sentences])\n",
    "maximum_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JZ6-h8kASMdD",
    "outputId": "2dfadf23-afad-4fe8-c7b9-6969b5c54691"
   },
   "outputs": [],
   "source": [
    "pre_X = [F.pad(torch.tensor(x), (0, maximum_length-len(x)), \"constant\", 0) for x in tokenized_sentences]\n",
    "X = torch.stack(pre_X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9qYXIGYR87O",
    "outputId": "56aa124a-459a-4443-eb5c-ba54f73640ae"
   },
   "outputs": [],
   "source": [
    "tokenizer_entities = [[tag2idx[w[2]] for w in s]for s in sentences]\n",
    "tokenizer_entities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R9YKRkANT1Qi",
    "outputId": "5ffed519-be08-4094-c5d2-b46f66c6f6fb"
   },
   "outputs": [],
   "source": [
    "maximum_tag_length = max([len(y) for y in tokenizer_entities])\n",
    "maximum_tag_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GpC7xBQ3UfCj",
    "outputId": "2e6f452f-d920-4492-8e8f-49c5a1acf42f"
   },
   "outputs": [],
   "source": [
    "F.pad(torch.tensor(tokenizer_entities[0]), (0, maximum_tag_length-len(tokenizer_entities[0])), \"constant\", tag2idx[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1IBhxmtThyS",
    "outputId": "2da643e9-502d-4f9e-d242-ca0f8ec451c3"
   },
   "outputs": [],
   "source": [
    "pre_y = [F.pad(torch.tensor(tokenizer_entities[i]), (0, maximum_tag_length-len(tokenizer_entities[i])), \"constant\", tag2idx[\"O\"]) for i in range(X.shape[0])]\n",
    "y = torch.stack(pre_y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yKpaoIa4Tp7M",
    "outputId": "7c3bce64-1be0-4bc5-ca43-5d3932f1565c"
   },
   "outputs": [],
   "source": [
    "y_categorical = torch.stack([F.one_hot(y[0], num_classes=num_tags) for i in range(y.shape[0])])\n",
    "y_categorical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jghi6ZetU0qf"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y_categorical, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZxM1vKQsVjl0"
   },
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(X_train, y_train)\n",
    "test_ds = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HOH2p0ohVjpd"
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WmAerTVhVjs0"
   },
   "outputs": [],
   "source": [
    "# Define a BiLSTM model for NER\n",
    "class BiLSTMForNER(nn.Module):\n",
    "    def __init__(self, num_words, num_tags, embedding_dim, hidden_dim=100, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        # Embedding layer that converts input words to embeddings\n",
    "        self.word_embeddings = None\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states with dimensionality hidden_dim //2.\n",
    "        # It will be bidirectional, meaning one LSTM for the forward pass and one for the backward pass.\n",
    "        self.lstm = None\n",
    "\n",
    "        # The linear layer maps from hidden state space to tag space\n",
    "        self.hidden2tag = None\n",
    "\n",
    "    def forward(self, sentence, hidden):\n",
    "        # Get the embeddings for the sentence\n",
    "        embeds = None\n",
    "        # Pass the embeddings through the LSTM; lstm_out shape is (len(sentence), batch_size, hidden_dim)\n",
    "        lstm_out, hidden = None\n",
    "        # Pass the LSTM output through the linear layer to get the tag space\n",
    "        tag_space = None\n",
    "        # Convert the tag space to tag scores, which are log probabilities of the tags\n",
    "        tag_scores = None\n",
    "        return tag_scores, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (\n",
    "            weight.new(2*self.num_layers, batch_size, self.hidden_dim // 2).zero_().to(device),\n",
    "            weight.new(2*self.num_layers, batch_size, self.hidden_dim // 2).zero_().to(device)\n",
    "        )\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z1JGVp1x30AY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "877hAFmB4lJK"
   },
   "outputs": [],
   "source": [
    "model = BiLSTMForNER(num_words, num_tags, embedding_dim, hidden_dim, num_layers).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aqa1-lovXv5m"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQ7dA6gkYV-K"
   },
   "outputs": [],
   "source": [
    "def kl_divergence_loss(outputs, targets, tagset_size):\n",
    "    \"\"\"\n",
    "    Calculate the KL Divergence loss for the outputs with respect to the targets\n",
    "    \"\"\"\n",
    "    # Flatten outputs and targets to compute the distribution loss across all batches and classes\n",
    "    outputs = outputs.view(-1, tagset_size)\n",
    "    targets = targets.view(-1, tagset_size)\n",
    "    # Compute KL Divergence\n",
    "    kl_loss = F.kl_div(F.log_softmax(outputs, dim=1), F.softmax(targets.to(float), dim=1), reduction='batchmean')\n",
    "    return kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3-ZFBRX4soC"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, optimizer, num_tags, learning_rate, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        hidden = model.init_hidden(batch_size)\n",
    "        total_loss = 0\n",
    "        for sentences, tag_indices in train_dataloader:\n",
    "            sentences = sentences.to(device)\n",
    "            tag_indices = tag_indices.to(device)\n",
    "            # Clear the gradients before each instance\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs, hidden = model(sentences, hidden)\n",
    "            loss = kl_divergence_loss(outputs, tag_indices, num_tags)\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            for hidden_state in hidden:\n",
    "              hidden_state.detach_()\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XmL_BS6FYkRN",
    "outputId": "65a2b5b6-5e52-4efd-ed9d-63d59adc1778"
   },
   "outputs": [],
   "source": [
    "train_model(model, train_dl, optimizer, num_tags, learning_rate=lr, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQO_F7D8uFvl"
   },
   "outputs": [],
   "source": [
    "ix2tag = {ix: tag for tag, ix in tag2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4iF9FY1uu25"
   },
   "outputs": [],
   "source": [
    "def argmax(iterable):\n",
    "    return max(enumerate(iterable), key=lambda x: x[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCyQIGqG6alm"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def evaluate_model(model, test_dataloader, ix_to_tag):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    true_tags = []\n",
    "    pred_tags = []\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    with torch.no_grad():\n",
    "        for sentence, tags in test_dataloader:\n",
    "            sentence = sentence.to(device)\n",
    "            tags = tags.to(device)\n",
    "            # Forward pass\n",
    "            tag_scores, hidden = model(sentence, hidden)\n",
    "            # Get the predicted tags\n",
    "            _, max_indices = torch.max(F.softmax(tag_scores, dim=1), dim=-1, keepdim=True)\n",
    "            one_hot = torch.zeros_like(F.softmax(tag_scores, dim=1))\n",
    "            one_hot.scatter_(-1, max_indices, 1)\n",
    "            # Update lists of true tags and predicted tags\n",
    "            true_tags.extend(tags.tolist())\n",
    "            pred_tags.extend(one_hot.tolist())\n",
    "    # Convert index sequences to tag name sequences\n",
    "\n",
    "\n",
    "    true_tag_names = [ix_to_tag[argmax(ix)] for ix in true_tags]\n",
    "    pred_tag_names = [ix_to_tag[argmax(ix)] if argmax(ix) < 17 else ix_to_tag[16] for ix in pred_tags ]\n",
    "\n",
    "    # Calculate and print the classification report\n",
    "    print(classification_report(true_tag_names, pred_tag_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-e1rAVBAqz_V",
    "outputId": "c9eafb58-ddca-4cfd-fa5e-70a7831f17ce"
   },
   "outputs": [],
   "source": [
    "evaluate_model(model, test_dl, ix2tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNgihwq_ugEW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
